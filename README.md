# TreinandoCNN
# üìÑ Documenta√ß√£o do Projeto de Classifica√ß√£o de D√≠gitos Manuscritos com CNN

Este projeto utiliza redes neurais convolucionais (CNNs) com TensorFlow/Keras para classificar imagens de d√≠gitos manuscritos. A base de dados utilizada est√° no arquivo `digitosmanuscritos.csv`.

---

## üì¶ 1. Carregamento e Pr√©-processamento dos Dados

```python
data = pd.read_csv("digitosmanuscritos.csv")
X = data.iloc[:, 1:].values.astype('float32')
y = data.iloc[:, 0].values
X /= 255.0
X = X.reshape(-1, 28, 28, 1)
y = tf.keras.utils.to_categorical(y, 10)
```

### Explica√ß√£o:

- **Leitura do CSV**: O arquivo `digitosmanuscritos.csv` √© lido usando `pandas`.
- **Separa√ß√£o de atributos e r√≥tulos**:
  - `X`: caracter√≠sticas das imagens (pixels), colunas de 1 em diante.
  - `y`: r√≥tulos (d√≠gitos), primeira coluna.
- **Normaliza√ß√£o**: os valores dos pixels s√£o normalizados para o intervalo `[0, 1]`.
- **Redimensionamento**: as imagens s√£o transformadas para o formato `[amostras, 28, 28, 1]` (formato adequado para CNNs).
- **One-hot encoding**: os r√≥tulos s√£o convertidos para o formato vetorial bin√°rio, adequado para `categorical_crossentropy`.

---

## üß† 2. Defini√ß√£o da Arquitetura da CNN

```python
def criar_modelo():
	model = tf.keras.models.Sequential([  
    tf.keras.Input(shape=(28, 28, 1)),  
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),  
    tf.keras.layers.MaxPooling2D((2, 2)),  
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),  
    tf.keras.layers.MaxPooling2D((2, 2)),  
    tf.keras.layers.Flatten(),  
    tf.keras.layers.Dense(128, activation='relu'),  
    tf.keras.layers.Dropout(0.5),  
    tf.keras.layers.Dense(10, activation='softmax')  
])  
	
	model.compile(optimizer='adam',  
    loss='categorical_crossentropy',  
    metrics=['accuracy'])  
	
	return model
```

### Estrutura da CNN:

1. **Entrada**: imagens 28x28 em escala de cinza (1 canal).
2. **Camadas convolucionais e de pooling**:
   - `Conv2D(32) + MaxPooling2D`
   - `Conv2D(64) + MaxPooling2D`
3. **Camada Flatten**: transforma os dados em vetor 1D.
4. **Camada densa (128 neur√¥nios) com Dropout (0.5)**: regulariza√ß√£o para evitar overfitting.
5. **Sa√≠da**: 10 neur√¥nios com ativa√ß√£o `softmax` (classifica√ß√£o multiclasse).
6. **Compila√ß√£o**: otimizador `adam`, fun√ß√£o de perda `categorical_crossentropy`, m√©trica `accuracy`.

---

## üèÉ 3. Treinamento, Avalia√ß√£o e Visualiza√ß√£o

```python
def treinar_e_testar(X, y, proporcao_treino):
	X_train, X_test, y_train, y_test = train_test_split(  
	X, y, train_size=proporcao_treino, random_state=42, stratify=y.argmax(axis=1)  
)  
  
model = criar_modelo()  
  
early_stop = EarlyStopping(  
    monitor='val_loss',  
    patience=3,  
    restore_best_weights=True  
)  
  
history = model.fit(  
    X_train, y_train,  
    epochs=50,  
    batch_size=128,  
    verbose=1,  
    validation_split=0.1,  
    callbacks=[early_stop]  
)  
  
# Plotar gr√°ficos de perda e acur√°cia  
plt.figure(figsize=(12, 5))  
  
plt.subplot(1, 2, 1)  
plt.plot(history.history['loss'], label='Treino')  
plt.plot(history.history['val_loss'], label='Valida√ß√£o')  
plt.title('Perda durante o treino')  
plt.xlabel('√âpoca')  
plt.ylabel('Loss')  
plt.legend()  
  
plt.subplot(1, 2, 2)  
plt.plot(history.history['accuracy'], label='Treino')  
plt.plot(history.history['val_accuracy'], label='Valida√ß√£o')  
plt.title('Acur√°cia durante o treino')  
plt.xlabel('√âpoca')  
plt.ylabel('Accuracy')  
plt.legend()  
  
filename_plot = f"training_plot_{int(proporcao_treino * 100)}_{int((1 - proporcao_treino) * 100)}.png"  
plt.savefig(filename_plot)  
plt.close()  
print(f"Gr√°ficos de treino salvos em: {filename_plot}")  
  
# Avalia√ß√£o  
loss, acc = model.evaluate(X_test, y_test, verbose=0)  
divisao = f"{round(proporcao_treino * 100)}_{round((1 - proporcao_treino) * 100)}"  
print(f"Acur√°cia com {divisao.replace('_', '/')}: {acc:.4f}")  
  
y_pred = model.predict(X_test)  
y_pred_classes = np.argmax(y_pred, axis=1)  
y_true = np.argmax(y_test, axis=1)  
  
print(classification_report(y_true, y_pred_classes))  
cm = confusion_matrix(y_true, y_pred_classes)  
  
# Criar a matriz em markdown  
markdown_lines = []  
header = "| |" + "|".join(str(i) for i in range(10)) + "|\n"  
separator = "|---" * 10 + "|---|\n"  
markdown_lines.append(header)  
markdown_lines.append(separator)  
for i, row in enumerate(cm):  
    row_str = f"|{i}|" + "|".join(str(cell) for cell in row) + "|\n"  
    markdown_lines.append(row_str)  
  
filename = f"confusion_matrix_{divisao}.md"  
with open(filename, "w") as f:  
    f.write(f"# Confusion Matrix ({divisao.replace('_', '/')})\n\n")  
    f.write(f"**Accuracy:** {acc:.4f}\n\n")  
    f.writelines(markdown_lines)  
  
print(f"\nMatriz de confus√£o salva como: {filename}")
```

### Etapas executadas:

#### a) Separa√ß√£o dos dados
- Utiliza `train_test_split` com estratifica√ß√£o para manter a propor√ß√£o de classes.

#### b) Treinamento
- Modelo criado com `criar_modelo()`.
- `EarlyStopping` interrompe o treino se a `val_loss` n√£o melhorar por 3 √©pocas.
- Utiliza `validation_split=0.1` durante o treino.

#### c) Visualiza√ß√£o
- Gera gr√°ficos de perda (`loss`) e acur√°cia (`accuracy`) ao longo das √©pocas.
- Salva como imagem com nome baseado na propor√ß√£o treino/teste, por exemplo: `training_plot_80_20.png`.

#### d) Avalia√ß√£o
- Calcula e exibe a acur√°cia final no conjunto de teste.
- Gera predi√ß√µes e imprime:
  - `classification_report`: precis√£o, recall e f1-score por classe.
  - `confusion_matrix`: matriz de confus√£o.

#### e) Salvamento da matriz de confus√£o
- Formata a matriz em Markdown.
- Salva o conte√∫do em um arquivo `.md` com nome como `confusion_matrix_80_20.md`.

---

## üß™ 4. Testes com Diferentes Propor√ß√µes de Treinamento/Teste

```python
proporcoes = [0.8, 0.9, 0.7]
for prop in proporcoes:
    treinar_e_testar(X, y, prop)
```

### O que acontece:
- Para cada propor√ß√£o definida (`80/20`, `90/10`, `70/30`), a fun√ß√£o `treinar_e_testar` √© executada.
- Isso permite comparar o desempenho da CNN em diferentes cen√°rios de disponibilidade de dados.

---

## üìÅ Arquivos Gerados

- **Imagens de gr√°ficos de treino**: `training_plot_XX_YY.png`
- **Matrizes de confus√£o em Markdown**: `confusion_matrix_XX_YY.md`

---

## üß∞ Bibliotecas Utilizadas

- `numpy`, `pandas`: manipula√ß√£o de dados.
- `tensorflow.keras`: cria√ß√£o e treino do modelo CNN.
- `sklearn`: divis√£o dos dados e avalia√ß√£o do modelo.
- `matplotlib`: visualiza√ß√£o de desempenho.
- `EarlyStopping`: parada antecipada para evitar overfitting.

